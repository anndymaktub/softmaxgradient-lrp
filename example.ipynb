{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "import numpy as np\n",
    "from utils.visualizations import GradCAM, GuidedGradCAM, GBP\n",
    "from utils.visualizations import LRP, CLRP, LRPA, LRPB, LRPE\n",
    "from utils.visualizations import SGLRP, SGLRPSeqA, SGLRPSeqB\n",
    "from utils.helper import heatmap\n",
    "import innvestigate.utils as iutils\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# limits tensorflow to a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be your trained model instead.\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "model = VGG16(\n",
    "    weights='imagenet'\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only the partial model is needed for the visualizers. Use innvestigate.utils.keras.graph.pre_softmax_tensors()\n",
    "partial_model = Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=iutils.keras.graph.pre_softmax_tensors(model.outputs),\n",
    "    name=model.name,\n",
    ")\n",
    "partial_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of input images\n",
    "# These values are set due to Keras Applications. Change this to a range suitable for your model.\n",
    "max_input = 151.061\n",
    "min_input = -123.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to load a list of images you want. \n",
    "orig_imgs = [img_to_array(load_img(\"data/images/zebra_elephant{}.jpg\".format(i+1), target_size=(224, 224))) for i in range(5)]\n",
    "input_imgs = np.copy(orig_imgs)\n",
    "print(np.shape(input_imgs))\n",
    "\n",
    "# preprocess input for model\n",
    "input_imgs = preprocess_input(input_imgs) #for built in keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only one from your list for example\n",
    "example_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(orig_imgs[example_id].astype(int))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which class you want to target.\n",
    "target_class = 340 # ImageNet \"zebra\"\n",
    "\n",
    "# GradCAM and GuidedGradCAM requires a specific layer\n",
    "target_layer = \"block5_pool\" # VGG only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "predictions = model.predict(input_imgs)\n",
    "pred_id = np.argmax(predictions[example_id])\n",
    "print(decode_predictions(predictions))\n",
    "print(\"prediction id:\", pred_id)\n",
    "print(\"target id:\", target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_relu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partial_gradcam_analyzer = GradCAM(\n",
    "    model=partial_model,\n",
    "    target_id=target_class,\n",
    "    layer_name=target_layer,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_partial_grad_cam = partial_gradcam_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_partial_grad_cam[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidedbackprop_analyzer = GBP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_guidedbackprop = guidedbackprop_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_guidedbackprop[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GuidedGradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidedgradcam_analyzer = GuidedGradCAM(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    layer_name=target_layer,\n",
    "    relu=False,\n",
    ")\n",
    "analysis_guidedgradcam = guidedgradcam_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_guidedgradcam[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_analyzer = LRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_lrp = lrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_lrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrp_analyzer = CLRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_clrp = clrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_clrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sglrp_analyzer = SGLRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_sglrp = sglrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_sglrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGLRP Sequential A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sglrpa_analyzer = SGLRPSeqA(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_sglrpa = sglrpa_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_sglrpa[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGLRP Sequential B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sglrpb_analyzer = SGLRPSeqB(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_sglrpb = sglrpb_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_sglrpb[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP Sequential A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpa_analyzer = LRPA(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_lrpa = lrpa_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_lrpa[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP Sequential B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpb_analyzer = LRPB(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_lrpb = lrpb_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_lrpb[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpe_analyzer = LRPE(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=use_relu,\n",
    ")\n",
    "analysis_lrpe = lrpe_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_lrpe[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
